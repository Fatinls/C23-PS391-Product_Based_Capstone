{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tavg</th>\n",
       "      <th>RH_avg</th>\n",
       "      <th>ff_x</th>\n",
       "      <th>ddd_x</th>\n",
       "      <th>Tavg_2</th>\n",
       "      <th>RH_avg_2</th>\n",
       "      <th>ff_x_2</th>\n",
       "      <th>ddd_x_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanggal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23-05-2021</th>\n",
       "      <td>24.3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>27.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24-05-2021</th>\n",
       "      <td>24.1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>27.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25-05-2021</th>\n",
       "      <td>24.4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26-05-2021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>27.8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27-05-2021</th>\n",
       "      <td>24.7</td>\n",
       "      <td>71.0</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>27.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tavg  RH_avg  ff_x  ddd_x  Tavg_2  RH_avg_2  ff_x_2  ddd_x_2\n",
       "Tanggal                                                                 \n",
       "23-05-2021  24.3    78.0     4     80    27.8      76.0       4       60\n",
       "24-05-2021  24.1    81.0     3    210    27.5      80.0       4      150\n",
       "25-05-2021  24.4    84.0     5     90    28.0      80.0       5      120\n",
       "26-05-2021   NaN     NaN     6     60    27.8      84.0       5      150\n",
       "27-05-2021  24.7    71.0     8     60    27.5      86.0       6      120"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'time-series-cuaca (1).csv', sep=',', header=0, low_memory=False, index_col=['Tanggal'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavg\n",
      "24.058847736625513\n",
      "RH_avg\n",
      "80.01373626373626\n",
      "ff_x\n",
      "4.5917808219178085\n",
      "ddd_x\n",
      "134.1095890410959\n",
      "Tavg_2\n",
      "27.207810320781032\n",
      "RH_avg_2\n",
      "79.58659217877096\n",
      "ff_x_2\n",
      "5.098630136986301\n",
      "ddd_x_2\n",
      "138.31506849315068\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column)\n",
    "    mean=df[column].mean()\n",
    "    print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tavg</th>\n",
       "      <th>RH_avg</th>\n",
       "      <th>ff_x</th>\n",
       "      <th>ddd_x</th>\n",
       "      <th>Tavg_2</th>\n",
       "      <th>RH_avg_2</th>\n",
       "      <th>ff_x_2</th>\n",
       "      <th>ddd_x_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanggal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23-05-2021</th>\n",
       "      <td>24.300000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>27.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24-05-2021</th>\n",
       "      <td>24.100000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>27.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25-05-2021</th>\n",
       "      <td>24.400000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26-05-2021</th>\n",
       "      <td>24.058848</td>\n",
       "      <td>80.013736</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>27.8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27-05-2021</th>\n",
       "      <td>24.700000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>27.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tavg     RH_avg  ff_x  ddd_x  Tavg_2  RH_avg_2  ff_x_2  \\\n",
       "Tanggal                                                                   \n",
       "23-05-2021  24.300000  78.000000     4     80    27.8      76.0       4   \n",
       "24-05-2021  24.100000  81.000000     3    210    27.5      80.0       4   \n",
       "25-05-2021  24.400000  84.000000     5     90    28.0      80.0       5   \n",
       "26-05-2021  24.058848  80.013736     6     60    27.8      84.0       5   \n",
       "27-05-2021  24.700000  71.000000     8     60    27.5      86.0       6   \n",
       "\n",
       "            ddd_x_2  \n",
       "Tanggal              \n",
       "23-05-2021       60  \n",
       "24-05-2021      150  \n",
       "25-05-2021      120  \n",
       "26-05-2021      150  \n",
       "27-05-2021      120  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(df.mean())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df\n",
    "scalers={}\n",
    "for i in df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    s_s = scaler.fit_transform(df1[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+ i] = scaler\n",
    "    df1[i]=s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = df1[:math.floor(0.75*730)], df1[math.floor(0.75*730):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "  #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "  #\n",
    "  X, y = list(), list()\n",
    "  for window_start in range(len(series)):\n",
    "    past_end = window_start + n_past\n",
    "    future_end = past_end + n_future\n",
    "    if future_end > len(series):\n",
    "      break\n",
    "    # slicing the past and future parts of the window\n",
    "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "    X.append(past)\n",
    "    y.append(future)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 90 8\n",
      "87 7 8\n"
     ]
    }
   ],
   "source": [
    "n_past = 90\n",
    "n_future =  7\n",
    "n_features = 8\n",
    "X_train, y_train = split_series(train.values,n_past, n_future)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))\n",
    "print(X_test.shape[0],X_test.shape[1],X_test.shape[2])\n",
    "print(y_test.shape[0],y_test.shape[1],y_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 90, 8)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 90, 16)       528         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 90, 16),     2112        ['conv1d[0][0]']                 \n",
      "                                 (None, 16),                                                      \n",
      "                                 (None, 16)]                                                      \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 8),          800         ['lstm[0][0]']                   \n",
      "                                 (None, 8),                                                       \n",
      "                                 (None, 8)]                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8)            0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 7, 8)         0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 7, 16)        1600        ['repeat_vector[0][0]',          \n",
      "                                                                  'lstm[0][1]',                   \n",
      "                                                                  'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 7, 8)         800         ['lstm_2[0][0]',                 \n",
      "                                                                  'lstm_1[0][1]',                 \n",
      "                                                                  'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 7, 8)        72          ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,912\n",
      "Trainable params: 5,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "\n",
    "# Add Conv1D layer\n",
    "encoder_cnn = tf.keras.layers.Conv1D(16, kernel_size=4, activation='relu', padding='causal')(encoder_inputs)\n",
    "\n",
    "encoder_l1 = tf.keras.layers.LSTM(16, return_sequences=True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_cnn)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "encoder_l2 = tf.keras.layers.LSTM(8, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "\n",
    "dropout_rate = 0.6\n",
    "dropout_layer = tf.keras.layers.Dropout(dropout_rate)\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(dropout_layer(encoder_outputs2[0]))\n",
    "\n",
    "decoder_l1 = tf.keras.layers.LSTM(16, return_sequences=True)(decoder_inputs, initial_state=encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(8, return_sequences=True)(decoder_l1, initial_state=encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
    "\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs, decoder_outputs2)\n",
    "\n",
    "model_e2d2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 13s 240ms/step - loss: 0.0349 - mae: 0.1981 - val_loss: 0.0148 - val_mae: 0.1350\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.0116 - mae: 0.1199 - val_loss: 0.0115 - val_mae: 0.1193\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.0108 - mae: 0.1133 - val_loss: 0.0117 - val_mae: 0.1180\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 2s 137ms/step - loss: 0.0106 - mae: 0.1128 - val_loss: 0.0115 - val_mae: 0.1180\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 0.0106 - mae: 0.1122 - val_loss: 0.0115 - val_mae: 0.1179\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 2s 127ms/step - loss: 0.0106 - mae: 0.1125 - val_loss: 0.0115 - val_mae: 0.1174\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 0.0106 - mae: 0.1122 - val_loss: 0.0114 - val_mae: 0.1175\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 2s 147ms/step - loss: 0.0106 - mae: 0.1126 - val_loss: 0.0115 - val_mae: 0.1179\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 3s 238ms/step - loss: 0.0106 - mae: 0.1129 - val_loss: 0.0116 - val_mae: 0.1182\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 3s 184ms/step - loss: 0.0106 - mae: 0.1125 - val_loss: 0.0119 - val_mae: 0.1197\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 2s 162ms/step - loss: 0.0106 - mae: 0.1125 - val_loss: 0.0116 - val_mae: 0.1186\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 2s 159ms/step - loss: 0.0106 - mae: 0.1123 - val_loss: 0.0114 - val_mae: 0.1171\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 2s 158ms/step - loss: 0.0107 - mae: 0.1129 - val_loss: 0.0115 - val_mae: 0.1177\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 0.0106 - mae: 0.1125 - val_loss: 0.0118 - val_mae: 0.1198\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 2s 160ms/step - loss: 0.0106 - mae: 0.1127 - val_loss: 0.0115 - val_mae: 0.1177\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 2s 160ms/step - loss: 0.0106 - mae: 0.1125 - val_loss: 0.0114 - val_mae: 0.1175\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 2s 156ms/step - loss: 0.0106 - mae: 0.1124 - val_loss: 0.0116 - val_mae: 0.1182\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.0106 - mae: 0.1126 - val_loss: 0.0115 - val_mae: 0.1175\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 2s 148ms/step - loss: 0.0106 - mae: 0.1127 - val_loss: 0.0120 - val_mae: 0.1197\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 2s 157ms/step - loss: 0.0107 - mae: 0.1132 - val_loss: 0.0116 - val_mae: 0.1179\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 0.0107 - mae: 0.1130 - val_loss: 0.0115 - val_mae: 0.1176\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 2s 155ms/step - loss: 0.0107 - mae: 0.1129 - val_loss: 0.0117 - val_mae: 0.1187\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 2s 157ms/step - loss: 0.0106 - mae: 0.1125 - val_loss: 0.0117 - val_mae: 0.1189\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 2s 159ms/step - loss: 0.0106 - mae: 0.1122 - val_loss: 0.0116 - val_mae: 0.1180\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 2s 160ms/step - loss: 0.0107 - mae: 0.1124 - val_loss: 0.0117 - val_mae: 0.1191\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.0108 - mae: 0.1135 - val_loss: 0.0117 - val_mae: 0.1187\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 2s 163ms/step - loss: 0.0106 - mae: 0.1127 - val_loss: 0.0114 - val_mae: 0.1169\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 2s 162ms/step - loss: 0.0106 - mae: 0.1126 - val_loss: 0.0116 - val_mae: 0.1181\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 2s 157ms/step - loss: 0.0108 - mae: 0.1127 - val_loss: 0.0115 - val_mae: 0.1180\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 2s 157ms/step - loss: 0.0107 - mae: 0.1130 - val_loss: 0.0119 - val_mae: 0.1186\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 2s 160ms/step - loss: 0.0107 - mae: 0.1131 - val_loss: 0.0117 - val_mae: 0.1185\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 2s 156ms/step - loss: 0.0106 - mae: 0.1124 - val_loss: 0.0117 - val_mae: 0.1185\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 0.0107 - mae: 0.1128 - val_loss: 0.0116 - val_mae: 0.1177\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 0.0106 - mae: 0.1126 - val_loss: 0.0115 - val_mae: 0.1176\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 0.0107 - mae: 0.1132 - val_loss: 0.0116 - val_mae: 0.1180\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 2s 158ms/step - loss: 0.0106 - mae: 0.1119 - val_loss: 0.0115 - val_mae: 0.1185\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 2s 162ms/step - loss: 0.0107 - mae: 0.1129 - val_loss: 0.0116 - val_mae: 0.1190\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 2s 158ms/step - loss: 0.0106 - mae: 0.1128 - val_loss: 0.0117 - val_mae: 0.1189\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 2s 159ms/step - loss: 0.0104 - mae: 0.1117 - val_loss: 0.0117 - val_mae: 0.1198\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 2s 159ms/step - loss: 0.0106 - mae: 0.1125 - val_loss: 0.0117 - val_mae: 0.1195\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 2s 158ms/step - loss: 0.0105 - mae: 0.1118 - val_loss: 0.0114 - val_mae: 0.1167\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 2s 158ms/step - loss: 0.0103 - mae: 0.1103 - val_loss: 0.0114 - val_mae: 0.1174\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 0.0103 - mae: 0.1106 - val_loss: 0.0117 - val_mae: 0.1196\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 2s 162ms/step - loss: 0.0102 - mae: 0.1094 - val_loss: 0.0117 - val_mae: 0.1194\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 2s 160ms/step - loss: 0.0101 - mae: 0.1087 - val_loss: 0.0120 - val_mae: 0.1185\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 2s 159ms/step - loss: 0.0101 - mae: 0.1083 - val_loss: 0.0117 - val_mae: 0.1187\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 2s 166ms/step - loss: 0.0100 - mae: 0.1078 - val_loss: 0.0114 - val_mae: 0.1174\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0113 - val_mae: 0.1167\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 0.0100 - mae: 0.1073 - val_loss: 0.0116 - val_mae: 0.1189\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 0.0099 - mae: 0.1067 - val_loss: 0.0121 - val_mae: 0.1211\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
    "# model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "# history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])\n",
    "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0447), loss=tf.keras.losses.Huber(),metrics=[\"mae\"])\n",
    "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),batch_size=32,verbose=1)#,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_e2d2=model_e2d2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,i in enumerate(train.columns):\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
    "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavg\n",
      "Day  1 :\n",
      "MAE-E2D2 :  0.637811130216752\n",
      "Day  2 :\n",
      "MAE-E2D2 :  0.6593541726298715\n",
      "Day  3 :\n",
      "MAE-E2D2 :  0.6842024660658561\n",
      "Day  4 :\n",
      "MAE-E2D2 :  0.6953946475324959\n",
      "Day  5 :\n",
      "MAE-E2D2 :  0.704669715618265\n",
      "Day  6 :\n",
      "MAE-E2D2 :  0.7065377421762752\n",
      "Day  7 :\n",
      "MAE-E2D2 :  0.7051371694981367\n",
      "\n",
      "RH_avg\n",
      "Day  1 :\n",
      "MAE-E2D2 :  4.53015084102236\n",
      "Day  2 :\n",
      "MAE-E2D2 :  4.590865124231097\n",
      "Day  3 :\n",
      "MAE-E2D2 :  4.645842716611665\n",
      "Day  4 :\n",
      "MAE-E2D2 :  4.668306986490886\n",
      "Day  5 :\n",
      "MAE-E2D2 :  4.682053752329158\n",
      "Day  6 :\n",
      "MAE-E2D2 :  4.795735501694954\n",
      "Day  7 :\n",
      "MAE-E2D2 :  4.903735106018768\n",
      "\n",
      "ff_x\n",
      "Day  1 :\n",
      "MAE-E2D2 :  1.0736358467189746\n",
      "Day  2 :\n",
      "MAE-E2D2 :  1.0524714239712418\n",
      "Day  3 :\n",
      "MAE-E2D2 :  1.067277354755621\n",
      "Day  4 :\n",
      "MAE-E2D2 :  1.0567679569639008\n",
      "Day  5 :\n",
      "MAE-E2D2 :  1.0481925229916627\n",
      "Day  6 :\n",
      "MAE-E2D2 :  1.035990780797498\n",
      "Day  7 :\n",
      "MAE-E2D2 :  1.0539227573350929\n",
      "\n",
      "ddd_x\n",
      "Day  1 :\n",
      "MAE-E2D2 :  53.8424002110273\n",
      "Day  2 :\n",
      "MAE-E2D2 :  56.00893454716123\n",
      "Day  3 :\n",
      "MAE-E2D2 :  57.85039143178655\n",
      "Day  4 :\n",
      "MAE-E2D2 :  58.97577684775166\n",
      "Day  5 :\n",
      "MAE-E2D2 :  60.58237369581201\n",
      "Day  6 :\n",
      "MAE-E2D2 :  59.844254592369346\n",
      "Day  7 :\n",
      "MAE-E2D2 :  61.31564445057135\n",
      "\n",
      "Tavg_2\n",
      "Day  1 :\n",
      "MAE-E2D2 :  0.8039329779293535\n",
      "Day  2 :\n",
      "MAE-E2D2 :  0.8324814237397293\n",
      "Day  3 :\n",
      "MAE-E2D2 :  0.8640969155848715\n",
      "Day  4 :\n",
      "MAE-E2D2 :  0.8635357140963483\n",
      "Day  5 :\n",
      "MAE-E2D2 :  0.8722413355745497\n",
      "Day  6 :\n",
      "MAE-E2D2 :  0.8781399449551622\n",
      "Day  7 :\n",
      "MAE-E2D2 :  0.8655718460319066\n",
      "\n",
      "RH_avg_2\n",
      "Day  1 :\n",
      "MAE-E2D2 :  3.753713744595922\n",
      "Day  2 :\n",
      "MAE-E2D2 :  3.7458474714004466\n",
      "Day  3 :\n",
      "MAE-E2D2 :  3.797682542481849\n",
      "Day  4 :\n",
      "MAE-E2D2 :  3.8792890895196095\n",
      "Day  5 :\n",
      "MAE-E2D2 :  3.8882174103933522\n",
      "Day  6 :\n",
      "MAE-E2D2 :  3.841704324315541\n",
      "Day  7 :\n",
      "MAE-E2D2 :  3.7391211516379643\n",
      "\n",
      "ff_x_2\n",
      "Day  1 :\n",
      "MAE-E2D2 :  1.2396857930325913\n",
      "Day  2 :\n",
      "MAE-E2D2 :  1.249662810358508\n",
      "Day  3 :\n",
      "MAE-E2D2 :  1.2461706194384345\n",
      "Day  4 :\n",
      "MAE-E2D2 :  1.26797044140169\n",
      "Day  5 :\n",
      "MAE-E2D2 :  1.259373582642654\n",
      "Day  6 :\n",
      "MAE-E2D2 :  1.2811157127906536\n",
      "Day  7 :\n",
      "MAE-E2D2 :  1.2909633099347695\n",
      "\n",
      "ddd_x_2\n",
      "Day  1 :\n",
      "MAE-E2D2 :  67.8293484216449\n",
      "Day  2 :\n",
      "MAE-E2D2 :  67.60491855665185\n",
      "Day  3 :\n",
      "MAE-E2D2 :  67.1634943293429\n",
      "Day  4 :\n",
      "MAE-E2D2 :  67.21425935591775\n",
      "Day  5 :\n",
      "MAE-E2D2 :  67.40932876762302\n",
      "Day  6 :\n",
      "MAE-E2D2 :  65.85169105968257\n",
      "Day  7 :\n",
      "MAE-E2D2 :  64.76343018981233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "for index,i in enumerate(train.columns):\n",
    "  print(i)\n",
    "  for j in range(1,8):\n",
    "    print(\"Day \",j,\":\")\n",
    "    print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = \"model/modelY.h5\"\n",
    "\n",
    "model_e2d2.save(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
